{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1001c433-4fca-4ba3-a670-10275b9274ad",
      "metadata": {
        "id": "1001c433-4fca-4ba3-a670-10275b9274ad"
      },
      "source": [
        "# Part 3: Translation with Flan-T5\n",
        "\n",
        "In this part you will experiment with Google Flan-T5 models for machine translation. The original T5 model was a unifed sequence-to-sequence encoder-decoder architecture pretrained on a variety of tasks including machine translation. The Flan line of models improved on the performance of the original T5 series.\n",
        "\n",
        "In this part we will only apply the models, not train them. We will evaluate our results using the [Bleu score](https://en.wikipedia.org/wiki/BLEU), a common (but not perfect) quantitative metric for evaluating the quality of translations. Flan-T5 also comes in several different model sizes: We will study the impact of model size on performance by considering several different versions of Flan-T5.\n",
        "\n",
        "**Learning objectives.** You will:\n",
        "1. Examine an encoder-decoder sequence-to-sequence Flan-T5 transformer model\n",
        "2. Apply Flan-T5 models to perform machine translation\n",
        "3. Evaluate the quality of machine translations by computing Bleu scores with respect to reference translations\n",
        "4. Study the affect\n",
        "\n",
        "While it is possible to complete this assignment using CPU compute, it may be slow. To accelerate your training, consider using GPU resources such as `CUDA` through the CS department cluster. Alternatives include Google colab or local GPU resources for those running on machines with GPU support."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5249219-8c67-4087-b2be-3f6c9982d951",
      "metadata": {
        "id": "b5249219-8c67-4087-b2be-3f6c9982d951"
      },
      "source": [
        "First, ensure that you have the `transformers` and `datasets` modules installed. We will use these modules for importing tokenizers, pretrained models, and datasets. You can run the following cells to try to install them with `pip` if needed. If you are using ondemand, ideally you would simply include `module load transformers` and `module load datasets` when making your initial reservation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9bfb3fa3-39f4-45ca-989d-31019c339100",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bfb3fa3-39f4-45ca-989d-31019c339100",
        "outputId": "4f181221-e487-46a1-e589-e9d53bc7690e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1f166e33-29ad-45b3-93f1-96b3f8173b62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f166e33-29ad-45b3-93f1-96b3f8173b62",
        "outputId": "fd030f98-f12a-48f8-9c36-9f90703eda50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.29.2)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d9aba23-9b2c-4aec-beda-a00cefa676df",
      "metadata": {
        "id": "4d9aba23-9b2c-4aec-beda-a00cefa676df"
      },
      "source": [
        "First we import the `flan-t5` tokenizer (shared across all model sizes) and demonstrate its characteristics and usage. Note that the API is the same as we saw previously for the `BERT` model -- may want to review the extra details in that earlier part.\n",
        "\n",
        "Note that the example contains both English and French text.\n",
        "\n",
        "(If you have trouble downloading the tokenizer, it is possible that you need to install the `sentencepiece` module, for example by `pip install sentencepiece`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca45c37c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SentencePiece in /opt/anaconda3/lib/python3.12/site-packages (0.2.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install SentencePiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4e637e38-7a1f-4eb3-91b4-e080daf23234",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "f9a85abb784f493c84c90ef45daf53ce",
            "c459b8e0d847455caa171aa11410dd23",
            "d32ef4e06545455d92db3ecfe7d39bb1",
            "ce0bf6c0eb594ce99e70a8d582d082c1",
            "2348d91acd1243b28ccb4b66d03dda6d",
            "0fb827fe443044718431db65056eec56",
            "2070ccc3e8c046108b40f16db86c666f",
            "afcb8f985d4140c8a8e87e69881bd72c",
            "aedbf272bd43424685913c88be88e49a",
            "cd6fafd3db4c4499abb4192ce214567d",
            "06a6a534d71741518dc28e5506e27522",
            "700546c4e4fc4693bbe1c2f781543b7b",
            "fd06aed400934fc2a20c1462d546ea48",
            "df75454dcfd44366b043a05999d3ddf3",
            "7b102c61daec4c2c863ab39f145738cc",
            "1dd4fb7a2bdf454594ae07c910e259e9",
            "d0c3ea5be13b478a80abbfb5974472ce",
            "f8b07b72eb95495e87e98809711859b0",
            "da5acdce8b224c9ca21e7a3a2331779b",
            "9ca6dfde179c44329f39863e87ed67b7",
            "4b6667f8f1114022922416192ffed592",
            "310ba1d9f53f4029a4f5a93b12a51266",
            "0b9fbfc50a4f411a98f091e6c2e16aa7",
            "630c8e79ea0f416694cfe3e04bf74867",
            "4fcbad5d03a7430f889c3588c2ae64ef",
            "56a5ccb809744c90aa676c8cd28debc8",
            "c59d8103cd5f434fa4fe3c5fef0586c1",
            "ef25545468984f8ca7897471a38f74c3",
            "787e6d629b8b48d2bd1b13eb304e2ab2",
            "e78ddf247b2a418592c3c616c4493af5",
            "c29ea8b153844dfca2e64c2a58bdb72a",
            "4995892cd8be4bf3bf9deb6c83730172",
            "f8736b4a52c243b993dfdfa3ef10ff54",
            "583c437a21254e1bb49bec206935d884",
            "b1ea0eaea24543dfa3d3932756a0665c",
            "550733b1c9e54b9ab6afb1a43cce74e0",
            "1322a370230c4104a4c42a4389717b2b",
            "8efc428d76234b9595a0e634b6075ebf",
            "f5f35adc196446998284a983ee370e29",
            "0c160d072ae8416697da2d35ea3a68d2",
            "22afb012676c4f18b46394b7b94a0f8d",
            "9ce15fb683934db8b87a346daff2ae18",
            "3ce7d1ef14c1447ca9105d8d04c6cc8e",
            "ac8f23924d30434b831ecbc846e4a24f"
          ]
        },
        "id": "4e637e38-7a1f-4eb3-91b4-e080daf23234",
        "outputId": "ecda47c0-c881-4e54-962b-593cf772089e",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "611552cfdd03479d919d9df7be61dd53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e671eaf9548544b0959188e4a88cd8e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dd5012a43df416c895abc469689168f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72e28120adeb45b988f0bea731f4eb2b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size:  32000\n",
            "{'input_ids': [[37, 385, 1001, 1712, 2085, 7, 16, 8, 2034, 1], [312, 4561, 3582, 9691, 5048, 247, 50, 25301, 1, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]}\n"
          ]
        }
      ],
      "source": [
        "# run but you do not need to modify this code\n",
        "\n",
        "from transformers import T5Tokenizer\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "\n",
        "print(\"Vocabulary size: \", tokenizer.vocab_size)\n",
        "tokenized = tokenizer([\"The little black cat sleeps in the window\",\n",
        "                       \"Le petit chat noir dort dans la fenêtre\"], padding='longest')\n",
        "print(tokenized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b009142-7ad6-423d-9447-cf362ac3e6ae",
      "metadata": {
        "id": "6b009142-7ad6-423d-9447-cf362ac3e6ae"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Below we import and preview the `flan-t5` model, beginning with the small version. You will also note that we are using 16-bit float representations to save on memory (this may be particularly relevant if you are using GPU compute for larger models, where the GPU may have limited memory available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ef167a43-0dba-41eb-bb2f-7966b1a9b34c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef167a43-0dba-41eb-bb2f-7966b1a9b34c",
        "outputId": "90dfa2c0-54bf-44d8-9cb8-3f2fdbbf5179",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d245539be0e549cb856751718f640bcf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92b3ad68046045b39936c2112dbcbad9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1ddb73866a04c2b95efbdb2d0990e29",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T5ForConditionalGeneration(\n",
            "  (shared): Embedding(32128, 512)\n",
            "  (encoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 6)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-7): 7 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (decoder): T5Stack(\n",
            "    (embed_tokens): Embedding(32128, 512)\n",
            "    (block): ModuleList(\n",
            "      (0): T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "              (relative_attention_bias): Embedding(32, 6)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1-7): 7 x T5Block(\n",
            "        (layer): ModuleList(\n",
            "          (0): T5LayerSelfAttention(\n",
            "            (SelfAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (1): T5LayerCrossAttention(\n",
            "            (EncDecAttention): T5Attention(\n",
            "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
            "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (2): T5LayerFF(\n",
            "            (DenseReluDense): T5DenseGatedActDense(\n",
            "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
            "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "              (act): NewGELUActivation()\n",
            "            )\n",
            "            (layer_norm): T5LayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_layer_norm): T5LayerNorm()\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# run, but you do not need to modify this code\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.float16)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfe34963-7122-4021-bb4b-63b1d210c480",
      "metadata": {
        "id": "bfe34963-7122-4021-bb4b-63b1d210c480"
      },
      "source": [
        "Examine the `model.parameters()`. How much memory (in kilobytes (KB), megabytes (MB), or gigabytes (GB)) should it take to store the model itself, given the 16-bit (or 2 byte) precision specified in the import? Briefly explain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "41035ae7-9718-4d2e-acab-7d6d26117c2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41035ae7-9718-4d2e-acab-7d6d26117c2f",
        "outputId": "44dfcbb4-2e43-4dd4-835b-68f5d1dd6fe8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# of model parameters: 76961152\n"
          ]
        }
      ],
      "source": [
        "# write code for task 1 here\n",
        "total = sum(p.numel() for p in model.parameters())\n",
        "print(f\"# of model parameters: {total}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89b89f06-b05c-4882-b0fd-708fd2ed34a3",
      "metadata": {
        "id": "89b89f06-b05c-4882-b0fd-708fd2ed34a3"
      },
      "source": [
        "*Briefly explain for task 1 here*\n",
        "\n",
        "As shown above, there are 76,961,152 parameters in the model. Given that each parameter will take 2 bytes to store, the total memory required for storing this model is 76,961,152 * 2 bytes = 153,922,304 bytes, or about 153.92 MB."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3b9a63d-7d7f-481f-a7a8-e7d87143c297",
      "metadata": {
        "id": "f3b9a63d-7d7f-481f-a7a8-e7d87143c297"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "Now we import and demonstrate the basic usage of the model `generate` method. This method autoregressively generates new text as we have discussed before in the context of causal language modeling, and supports different approaches (greedy, beam search, and sampling). The `generate` method API is [documented here](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/text_generation#transformers.GenerationMixin.generate).\n",
        "\n",
        "The example below demonstrates encoding a *batch* of inputs and passing them to the model for autoregressive generation. The printed output is generated by the model for the first and second input in the batch respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "57177033-b02f-4e4a-afb0-f380313e3731",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57177033-b02f-4e4a-afb0-f380313e3731",
        "outputId": "00225117-d57e-4969-e8e5-cb4450455b21",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0,   37, 1712,   19,    3,    9, 1712,    5,    1],\n",
            "        [   0,    3,   88,   19,    3,    9, 1782,    1,    0]])\n",
            "The cat is a cat.\n",
            "he is a dog\n"
          ]
        }
      ],
      "source": [
        "# run but you do not need to modify this code\n",
        "\n",
        "input_text = [\"The little black cat sleeps in the window\", \"The dog runs in the field\"]\n",
        "encoded = tokenizer(input_text, return_tensors=\"pt\", padding=\"longest\")\n",
        "\n",
        "outputs = model.generate(**encoded, max_new_tokens=100)\n",
        "print(outputs)\n",
        "\n",
        "for out in outputs:\n",
        "    print(tokenizer.decode(out, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "baa24589-2848-4928-b8c4-5869b9e31112",
      "metadata": {
        "id": "baa24589-2848-4928-b8c4-5869b9e31112"
      },
      "source": [
        "Note that the model did not translate the inputs. That is by design: Flan-T5 was pretrained on several different tasks including but not limited to machine translation.\n",
        "\n",
        "In order to use the model for translation, we need to **prompt it** to do so, providing context (literally) connecting to its pretraining. There are several different promptings that should work, we demonstrate two below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a5f8c4dc-11cd-401f-bb8a-c08fe7baba8a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5f8c4dc-11cd-401f-bb8a-c08fe7baba8a",
        "outputId": "5b766cd1-cc37-48e8-a3d9-3f6b412dc8d3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La petite cat noir s'est en vertu de la fenêtre.\n",
            "Le chien s'est en dehors de la terre.\n"
          ]
        }
      ],
      "source": [
        "# run but you do not need to modify this code\n",
        "\n",
        "input_text = [\"The little black cat sleeps in the window\", \"The dog runs in the field\"]\n",
        "prompt = \"Translate English into French: \"\n",
        "prompted_text = [prompt + in_text for in_text in input_text]\n",
        "encoded = tokenizer(prompted_text, return_tensors=\"pt\", padding=\"longest\")\n",
        "\n",
        "outputs = model.generate(**encoded, max_new_tokens=100)\n",
        "\n",
        "for out in outputs:\n",
        "    print(tokenizer.decode(out, skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5577a4f-fbb6-43dc-a0cc-9164af8d2ab7",
      "metadata": {
        "id": "b5577a4f-fbb6-43dc-a0cc-9164af8d2ab7"
      },
      "source": [
        "For this task, your goal is use the model to translate a large collection of German text into English, drawing from a paired translation of the novel Jane Eyre. Below we download and prepare the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b6bmJUprJjyO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6bmJUprJjyO",
        "outputId": "1b0cad88-4483-49f7-a48d-afe2b74727d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.3.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.29.2)\n",
            "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4f2655d1-f62a-4e32-a083-c6dc45085ba8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319,
          "referenced_widgets": [
            "60a75d8c9af44ba6951e365f682155ba",
            "60a891c6e6754d39911ac41fe453d830",
            "f67d1244a96448f0b20fd0dc07a6a53a",
            "47cbbb9448084ad4a508eb013b04f539",
            "d33f105722fd49bfac56a9df4a60fcad",
            "65db3bd502ff492ab657e795cf06e1db",
            "a2c9c4013ede49f9ae9c0c0f6ebd004f",
            "8f8f4b6ced684bf0a8b9c5518e936dde",
            "bbf890869d0945c6ab5bdd59402814f3",
            "d1a19f00b7c7401f9061ae3579979a17",
            "2133d9f9442f454cb209dc5e66178e42"
          ]
        },
        "id": "4f2655d1-f62a-4e32-a083-c6dc45085ba8",
        "outputId": "6bdddd07-e2d8-4eb4-9328-b98c7a5123ee",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e6c4087cd2b4215ab09f228f9192726",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/28.1k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 101:\n",
            "German: Dieser Vorwurf meiner Abhängigkeit war in meinen Ohren fast zum leeren, bedeutungslosen Singsang geworden, sehr schmerzlich und bedrückend, aber nur halb verständlich.\n",
            "English: This reproach of my dependence had become a vague sing-song in my ear: very painful and crushing, but only half intelligible.\n",
            "\n",
            "Example 102:\n",
            "German: Nun fiel auch Miß Abbot ein: »Und Sie sollten auch nicht denken, daß Sie mit den Fräulein Reed und Mr. Reed auf gleicher Stufe stehen, weil Mrs. Reed Ihnen gütig erlaubt, mit ihren Kindern erzogen zu werden.\n",
            "English: Miss Abbot joined in-- \"And you ought not to think yourself on an equality with the Misses Reed and Master Reed, because Missis kindly allows you to be brought up with them.\n",
            "\n",
            "Example 103:\n",
            "German: Diese werden einmal ein großes Vermögen haben, und Sie sind arm. Sie müssen demütig und bescheiden sein und versuchen, sich den andern angenehm zu machen.«\n",
            "English: They will have a great deal of money, and you will have none: it is your place to be humble, and to try to make yourself agreeable to them.\"\n",
            "\n",
            "Total examples loaded: 500\n"
          ]
        }
      ],
      "source": [
        "# run but you do not need to modify this code\n",
        "\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class OpusDataset(Dataset):\n",
        "    def __init__(self, dataset_stream, num_examples):\n",
        "        # Convert streaming dataset to list for random access\n",
        "        self.examples = list(dataset_stream.take(num_examples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.examples[idx]\n",
        "\n",
        "# Load the dataset in streaming mode\n",
        "dataset_stream = load_dataset(\n",
        "    \"opus_books\",\n",
        "    \"de-en\",\n",
        "    split=\"train\",\n",
        "    streaming=True\n",
        ")\n",
        "\n",
        "# Create instance of custom dataset\n",
        "dataset = OpusDataset(dataset_stream, num_examples=500)\n",
        "\n",
        "# Print a few examples to verify\n",
        "for i in range(100, 103):\n",
        "    print(f\"\\nExample {i+1}:\")\n",
        "    print(f\"German: {dataset[i]['translation']['de']}\")\n",
        "    print(f\"English: {dataset[i]['translation']['en']}\")\n",
        "print(f\"\\nTotal examples loaded: {len(dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eded5cd5-b650-4057-a19a-3265eb25f0b3",
      "metadata": {
        "id": "eded5cd5-b650-4057-a19a-3265eb25f0b3"
      },
      "source": [
        "**Use the Flan-T5 model to translate all of the German text in the dataset into English.** Even with GPU compute, this may take several minutes, but should not take hours. We encourage you to add some output every 10 or 50 examples so that you can track the progress, though you are not required to do so.\n",
        "\n",
        "**Select at least three examples from the dataset and print the model translation as well as the real English text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "9cb5fc49-28eb-4ce5-8297-0999c70eed9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cb5fc49-28eb-4ce5-8297-0999c70eed9a",
        "outputId": "d31aae6a-8a8e-4df2-c5c8-0a41861dfa4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Example 10:\n",
            "German: »Was sagt denn Bessie, daß ich gethan habe?« fragte ich.\n",
            "Prediction: \"How is Bessie saying that I have been?\" I asked.\n",
            "\n",
            "Example 20:\n",
            "German: Es waren jene, die von den Verstecken der Seevögel handelten, von jenen einsamen Felsen und Klippen, welche nur sie allein bewohnen, von der Küste Norwegens, die von ihrer äußersten südlichen Spitze, dem Lindesnäs bis zum Nordkap mit Inseln besäet ist. Wo der nördliche Ozean, in wildem Wirbel Um die nackten, öden Inseln tobt Des ultima Thule; und das atlantische Meer Sich stürmisch zwischen die Hebriden wälzt.\n",
            "Prediction: It was those who were surrounded by the sand and sand that only they could afford, from the Norwegen coast, which is a sand-covered island, which is a sand-covered island, which is a sand-covered island, and the sand-covered island is a sand-covered island, and the sand-covered island is a sand-covered island, which is\n",
            "\n",
            "Example 30:\n",
            "German: »Bah, Frau Träumerin!« ertönte John Reeds Stimme; dann hielt er inne; augenscheinlich war er erstaunt, das Zimmer leer zu finden. »Wo zum Teufel ist sie denn?« fuhr er fort, »Lizzy!\n",
            "Prediction: \"Bah, Frau Träumerin!\" ertönt John Reed's voice; then he hielt him; he was a bit sluggish, and he was a bit sluggish, \"Wo the Teufel is it this?\" he frightened him, \"Lizzy!\"\n",
            "\n",
            "Example 40:\n",
            "German: Gewöhnlich pflegte er sich bei Tische so vollzupfropfen, daß er gallig wurde; das machte seine Augen trübe und seine Wangen schlaff.\n",
            "Prediction: He is a very well-known sexy man who has been a sexy man for a long time.\n",
            "\n",
            "Example 50:\n",
            "German: An Johns Beschimpfungen gewöhnt, fiel es mir niemals ein, irgend etwas auf dieselben zu erwidern; ich dachte nur daran, wie ich den Schlag ertragen sollte, der unfehlbar auf die Schimpfworte folgen würde.\n",
            "Prediction: In John's cases, I am not a single one of those who have been able to do anything to the same; I thought only to be able to do what I should do to the same problem.\n",
            "\n",
            "Example 60:\n",
            "German: »Du böser, grausamer Bube!« schrie ich. »Du bist wie ein Mörder – du bist wie ein Sklaventreiber – du bist wie die römischen Kaiser!«\n",
            "Prediction: \"The böser, grausamer Bube!\" I think. \"The böser, grausamer Bube!\" I think. \"The böser, grausamer Bube!\" I think. \"The böser, grausamer Bube!\" I think. \"The böser, grausamer Bube!\" I think. \"The böser, grausamer Bube!\" I\n",
            "\n",
            "Example 70:\n",
            "German: Man trennte uns: dann vernahm ich die Worte: »Du liebe Zeit! Du liebe Zeit!\n",
            "Prediction: Man threw us: then I saw the words: \"You love time! You love time!\n",
            "\n",
            "Example 80:\n",
            "German: »Schämen Sie sich! Schämen Sie sich!« rief die Kammerjungfer.\n",
            "Prediction: »Shut up! Put up! Put up! » sat down!\n",
            "\n",
            "Example 90:\n",
            "German: »Miß Abbot, borgen Sie mir Ihre Strumpfbänder; die meinen würde sie augenblicklich zerreißen.«\n",
            "Prediction: \"I'm in Abbot, I'm a snobby snob; I'm a snobby snobby snobby snobby snobby snobby snobby snobby snobby snobby snobby sno\n",
            "\n",
            "Example 100:\n",
            "German: Auf diese Worte fand ich nichts zu erwidern; sie waren mir nicht mehr neu; so weit ich in meinem Leben zurückdenken konnte, hatte ich Winke desselben Inhalts gehört.\n",
            "Prediction: I was not able to understand them, but I was not able to understand them. I had no idea what they were.\n",
            "\n",
            "Example 110:\n",
            "German: Und doch war es eins der schönsten und prächtigsten Gemächer im Herrenhause. Wie ein Tabernakel stand im Mittelpunkt desselben ein Bett von massiven Mahagonipfeilern getragen und mit Vorhängen von dunkelrotem Damast behängt; die beiden großen Fenster, deren Rouleaux immer herabgelassen waren, wurden durch Gehänge und Faltendraperien vom selben Stoffe halb verhüllt; der Teppich war rot; der Tisch am Fußende des Bettes war mit einer hochroten Decke belegt; die Wände waren mit einem Stoffe behängt, der auf lichtbraunem Grunde ein zartes rosa Muster trug; die Garderobe, der Toilettetisch, die Stühle waren aus dunklem, poliertem Mahagoni angefertigt.\n",
            "Prediction: And it was one of the most important and most important gems in the Herrenhaus. As a tabernacle stand in the same direction a Bett of massive Mahagonipfeiders was found and with fallen debris from the same substances, the two large windows, which were always shabby, were re-painted, the rug was rotted, the floor was rotted, the walls were a rudder, the walls were\n",
            "\n",
            "Example 120:\n",
            "German: In ihm sah alles noch kühler und hohler und düsterer aus als in Wirklichkeit, und die seltsame, kleine Gestalt, die mir aus ihm entgegenblickte, mit weißem Gesicht und Armen, die grell aus der Dunkelheit hervorleuchteten, mit Augen, die vor Furcht hin- und herrollten, wo sonst alles bewegungslos war – diese kleine Gestalt sah aus, wie ein wirkliches Gespenst; ich dachte an eins jener zarten Phantome, halb Elfe, halb Kobold, wie sie in Bessies Dämmerstunden-Geschichten aus einsamen, wilden Schluchten und düsteren Mooren hervorkamen und sich dem Auge des nächtlichen Wanderers zeigten.\n",
            "Prediction: In his eyes, he has all the slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and slacks and\n",
            "\n",
            "Example 130:\n",
            "German: John wurde niemals bestraft, niemand widersprach ihm jemals, obgleich er den Tauben die Hälse umdrehte, die jungen Hühner umbrachte, die Hunde auf die Schafe hetzte, den Weinstock im Treibhause seiner Trauben beraubte und von den seltensten Pflanzen die Knospen abriß; er nannte seine Mutter sogar »liebe Alte«; nahm durchaus keine Rücksicht auf ihre Wünsche; zerriß und beschmutzte ihre seidenen Kleider nicht selten, – und doch war er »ihr einziger Liebling«.\n",
            "Prediction: John was not a savage, he was a savage, a savage, a savage, a savage, a savage, a savage, a savage, a savage, a savage, a savage, a savage, a savage, a\n",
            "\n",
            "Example 140:\n",
            "German: Es war auch nicht ihre Pflicht, mit Liebe auf ein Geschöpf zu blicken, welches mit keiner einzigen Seele sympathisieren konnte; ein heterogenes Geschöpf, welches ihr direktes Gegenteil in Temperament, in Fähigkeiten und Neigungen war; ein nutzloses Geschöpf, welches ihrem Interesse nicht dienen, zu ihrem Vergnügen nichts beitragen konnte; ein strafbares Geschöpf, welches die Keime der Empörung über die ihm widerfahrende Behandlung in sich nährte, ein Geschöpf, das die tiefste Verachtung für ihren Verstand, ihr Urteilsvermögen nährte.\n",
            "Prediction: It was also not their duty to see a sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex-sex\n",
            "\n",
            "Example 150:\n",
            "German: Es mußte allerdings ärgerlich sein, sich durch ein unter solchen Umständen gegebenes Versprechen genötigt zu sehen, einem fremden Kinde, das sie nicht lieben konnte, die Eltern zu ersetzen, und es ertragen zu müssen, daß eine unsympathische Fremde sich unaufhörlich in ihren Familienkreis drängte.\n",
            "Prediction: But it is also important to see how a person who is not a loved one could see a person who is not a loved one who could not be loved by their parents and to be able to see that a sympathic Fremde is unaffected in their family circle.\n",
            "\n",
            "Example 160:\n",
            "German: »Miß Eyre, sind Sie krank?« fragte Bessie. »Welch ein fürchterlicher Lärm!\n",
            "Prediction: \"Miß Eyre, are you krank?\" asked Bessie. \"Welch a fortnight!\n",
            "\n",
            "Example 170:\n",
            "German: »Abbot und Bessie, ich glaube, daß ich Befehl gegeben habe, Jane Eyre in dem roten Zimmer zu lassen, bis ich selbst sie holen würde?«\n",
            "Prediction: \"Abbot and Bessie, I believe that I have given you the command to let Jane Eyre in the roten rooms, but I would just like to leave them?\"\n",
            "\n",
            "Example 180:\n",
            "German: In ihren Augen war ich eine frühreife Schauspielerin; sie sah in der That auf mich wie auf eine Zusammensetzung der heftigsten Leidenschaften, eines niedrigen, gemeinen Geistes und gefährlicher Falschheit.\n",
            "Prediction: In their eyes they were a young sailor; they were a sailor in the same way as a sailor in the same way as a sailor in the same way as a sailor in the same way as a sailor in the same way as a sailor in the same way as a sailor in the same way as a sailor in the\n",
            "\n",
            "Example 190:\n",
            "German: Es war Nacht, eine Kerze brannte auf dem Tische; Bessie stand am Fußende meines Bettes und hielt eine Waschschüssel in der Hand, ein Herr saß auf einem Lehnstuhle neben mir und beugte sich über mich.\n",
            "Prediction: It was night, a sleeve on the table; a sleeve on the floor, a sleeve on the floor, a sleeve on the floor, a sleeve on the floor, a sleeve on the floor, a sleeve on the floor, a sleeve on the floor, a sleeve on\n",
            "\n",
            "Example 200:\n",
            "German: »Nun, dann werde ich auch schlafen gehen, denn es ist schon nach Mitternacht; aber Sie können mich rufen, wenn Sie während der Nacht irgend etwas brauchen.«\n",
            "Prediction: \"No, then I will also sleep, because it is already after Mitternacht; but you can call me if you need anything.\n",
            "\n",
            "Example 210:\n",
            "German: Sarah kam mit ihr zurück; beide gingen zu Bett; sie flüsterten wenigstens noch eine halbe Stunde mit einander, bevor sie einschliefen.\n",
            "Prediction: Sarah went back to Bett, and they went to bed at least a half hour before they went to bed.\n",
            "\n",
            "Example 220:\n",
            "German: Diese Lage der Dinge wäre für mich ein Paradies des Friedens gewesen, für mich, die ich nur an ein Dasein voll unaufhörlichen Tadels und grausame Sklaverei gewöhnt war, – aber in der That waren meine Nerven jetzt in einem solchen Zustande, daß keine Ruhe sie mehr sänftigen, kein Vergnügen sie mehr freudig erregen konnte. Bessie war unten in der Küche gewesen und brachte mir jetzt einen Kuchen herauf, der auf einem gewissen, bunt gemalten Porzellanteller lag, dessen Paradiesvogel, welcher sich auf einem Kranz von Maiglöckchen und Rosenknospen schaukelte, stets eine enthusiastische Bewunderung in mir wach gerufen hatte.\n",
            "Prediction: This situation of the things would have been a paradise for me, which I only had a full unauditical Tadel and grausame Sklaverei, but in which I had no desire to feel more relaxed, no more sexy, no more sexy, no more sexy, no more sexy, no more sexy, no more sexy, no more sexy,\n",
            "\n",
            "Example 230:\n",
            "German: »Als wir durch Wald und Flur streiften,\n",
            "Prediction: »We are streifed by the woods and the sands.\n",
            "\n",
            "Example 240:\n",
            "German: Er nimmt an sein Herz das Waisenkind! Das ist meine Hoffnung, die Kraft mir giebt, Daß Gott da droben sein Kind doch liebt. Bei ihm dort oben die Heimat ich find', Er liebt auch das arme Waisenkind!\n",
            "Prediction: He takes his wife the Waisenkind! That is my hope, the courage I have to say, that God will do his thing. He also takes his wife the Waisenkind.\n",
            "\n",
            "Example 250:\n",
            "German: »Nun, Sie haben geweint, Miß Jane Eyre, wollen Sie mir nicht sagen, weshalb?\n",
            "Prediction: \"No, you have been told, Mrs Jane Eyre, I want you not to say, therefore?\n",
            "\n",
            "Example 260:\n",
            "German: Nachdem er mich lange mit Muße betrachtet hatte, sagte er:\n",
            "Prediction: After I had been a little bit of a snob, I said:\n",
            "\n",
            "Example 270:\n",
            "German: Nun, was war es denn?« fragte Mr. Lloyd weiter, nachdem Bessie gegangen war.\n",
            "Prediction: Well, what was that?'' Mr. Lloyd asked, after Bessie was killed.\n",
            "\n",
            "Example 280:\n",
            "German: Fürchten Sie sich jetzt bei Tage auch noch?«\n",
            "Prediction: What are you doing now?\n",
            "\n",
            "Example 290:\n",
            "German: Wiederum hielt ich inne, dann rief ich kindisch aus:\n",
            "Prediction: I'm not a fan of it, but I'm kind of a fan of it.\n",
            "\n",
            "Example 300:\n",
            "German: »Niemanden, der mit Ihrem Vater verwandt war?«\n",
            "Prediction: \"Niemanden, which you saw with your father?\"\n",
            "\n",
            "Example 310:\n",
            "German: Gehören sie zur arbeitenden Klasse?«\n",
            "Prediction: What do you do to work your way through the sand?\n",
            "\n",
            "Example 320:\n",
            "German: »Ist das Ihre Herrin, Wärterin?« fragte Mr. Lloyd,\n",
            "Prediction: Mr. Lloyd, I'm asking you to take a look at the 'stuff'.\n",
            "\n",
            "Example 330:\n",
            "German: »Ich auch, ich auch – mit geschmorten Zwiebeln.\n",
            "Prediction: \"I also, I also – with a swoopy Zwiebeln.\n",
            "\n",
            "Example 340:\n",
            "German: Ich hörte, wie er mit stammelnden Lauten eine Geschichte begann »wie diese abscheuliche Jane Eyre« einer wilden Katze gleich auf ihn gesprungen sei; mit strenger Stimme unterbrach ihn seine Mutter.\n",
            "Prediction: I heard, as he was with the savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely savagely\n",
            "\n",
            "Example 350:\n",
            "German: Mrs. Reed war schnell wieder gefaßt; sie schüttelte mich heftig, sie ohrfeigte mich aus allen Kräften und verließ mich dann ohne eine Silbe zu sprechen.\n",
            "Prediction: Mrs. Reed was quickly re-elected; they re-elected me, re-elected me from all forces and re-elected me again without a silence.\n",
            "\n",
            "Example 360:\n",
            "German: In dieses Bettchen nahm ich auch stets meine Puppe mit; jedes menschliche Wesen muß etwas lieben, und da mir jeder andere Gegenstand für meine Liebe fehlte, fand ich meine Glückseligkeit darin, ein farbloses, verblaßtes Gebilde zu lieben, das noch häßlicher als eine Miniatur-Vogelscheuche war.\n",
            "Prediction: In this case, I have always been a fan of the human spirit, and every other person should be a good friend, and I am glad that I have a chance to be a good friend, which is still a very important part of the miniaturization process.\n",
            "\n",
            "Example 370:\n",
            "German: Anfänglich hatte sie ihr Geld in allen möglichen Winkeln und Ecken, in altes Lockenpapier oder in Lumpen gewickelt, versteckt; aber als einige dieser aufgespeicherten Schätze von dem Stubenmädchen entdeckt worden, willigte Eliza, welche fürchtete, eines Tages ihr ganzes Hab und Gut zu verlieren, darein, es ihrer Mutter gegen unerhörte Wucherzinsen – fünfzig oder sechzig Prozent – anzuvertrauen. Diese Zinsen trieb sie regelmäßig jedes Vierteljahr ein und führte mit ängstlicher Sorgfalt in einem kleinen Notizbuche hierüber Rechnung.\n",
            "Prediction: In fact, they had their money in all possible cash and earls, in other lockets or in Lumpen, and as some of these stored shackles of the Stubenmädchen discovered, Eliza, who for the first time, has lost her whole life and a lot of money, but she is a mother against unerhörte Wucherzinsen – five or six percent – and she has a small note in\n",
            "\n",
            "Example 380:\n",
            "German: – Bevor ich antwortete, zog ich noch einmal an der Fensterklinke, denn ich wollte dem Vogel gern sein kleines Mahl sichern; die Klinke gab nach, ich streute die Brosamen aus, einige auf das steinerne Gesimse, andere auf die Zweige des Kirschbaumes; dann erst schloß ich das Fenster und entgegnete:\n",
            "Prediction: – I'm asking you to see the window, because I wanted the Vogel to be a little bit more careful; the window was a little bit stale; the window was a little bit stale; the window was a little bit stale; the window was a little bit stale; the window was a little bit stale; the window was a little bit stale; the window was a little bit\n",
            "\n",
            "Example 390:\n",
            "German: Ich fürchtete mich, in die Kinderstube zurückzugehen; ich fürchtete mich, in das Wohnzimmer einzutreten! Zehn Minuten stand ich ängstlich zögernd da; das heftige Klingeln der Glocke im Frühstückszimmer entschied: ich mußte eintreten.\n",
            "Prediction: I want to go back to the playground, and I want to go back to the living room, and I want to go back to the living room, and I want to go back to the living room, and I want to go back to the living room.\n",
            "\n",
            "Example 400:\n",
            "German: Als ich diese Worte aussprach, blickte ich auf; er erschien mir wie ein großer Mann, aber ich war ja so klein; seine Züge waren groß und wie alle übrigen Linien seiner Gestalt hart und scharf.\n",
            "Prediction: As I said this word, I saw it, and I saw it as a great man, but I was so small; his eyes were big and as all other lines of his shape were hard and sharp.\n",
            "\n",
            "Example 410:\n",
            "German: »Sie kommen in die Hölle,« lautete meine schnelle und orthodoxe Antwort.\n",
            "Prediction: \"You come in the mountains,« I ask my quick and orthodox answer.\n",
            "\n",
            "Example 420:\n",
            "German: Erst vor zwei oder drei Tagen habe ich ein kleines Kind von fünf Jahren begraben – ein gutes Kind, dessen Seele jetzt im Himmel ist.\n",
            "Prediction: I have been a little bit of a snob, and I have been a little bit of a snob, and I have been a little bit of a snob, and I have been a little bit of a snob, and I have been a little bit of a snob, and I have been a little bit of a snob\n",
            "\n",
            "Example 430:\n",
            "German: Lieben Sie Ihre Bibel?«\n",
            "Prediction: Do you want to pay your bill?\n",
            "\n",
            "Example 440:\n",
            "German: Ich erwähne dieser Sache in deiner Gegenwart, Jane, damit du nicht versuchst, auch Mr. Brocklehurst täuschen zu wollen.«\n",
            "Prediction: I give this matter a second chance, Jane, so I do not wish to do so, Mr. Brocklehurst, to do so.»\n",
            "\n",
            "Example 450:\n",
            "German: Konsequenz und Festigkeit, mein lieber Mr. Brocklehurst, ich befürworte Konsequenz in allen Dingen!«\n",
            "Prediction: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
            "\n",
            "Example 460:\n",
            "German: »Das werde ich thun, Madame.\n",
            "Prediction: \"That will be my, Madame.\n",
            "\n",
            "Example 470:\n",
            "German: Geh wieder in die Kinderstube zurück!« In meinem Blicke oder in meinen Bewegungen mußte sie etwas herausforderndes gesehen haben, denn sie sprach in heftigster, wenn auch unterdrückter Bewegung.\n",
            "Prediction: If you're in the playground or in your movements, you'll have to ask them some questions, because they're in a sleazy way when they're slammed.\n",
            "\n",
            "Example 480:\n",
            "German: »Ich bin glücklich, daß Sie nicht meine Blutsverwandte sind. Niemals, so lange ich lebe, werde ich Sie wieder Tante nennen.\n",
            "Prediction: I am happy that you are not my Blutsverwandte, but I will be able to say that I will again call you Tante.\n",
            "\n",
            "Example 490:\n",
            "German: Und diese Geschichte – gerade so, wie ich sie jetzt erzähle – werde ich jedem erzählen, der mich frägt.\n",
            "Prediction: And this story – just as I've seen it now – will be a part of every story I've seen.\n",
            "\n",
            "Example 500:\n",
            "German: Du kannst mir glauben, ich wünsche nichts anderes, als dir eine Freundin zu sein.«\n",
            "Prediction: I'm sorry, I'm sorry, but I'm sorry, but I'm sorry, but I'm sorry.\n",
            "\n",
            "Sample Model Translations vs. Ground Truth:\n",
            "\n",
            "Example 101:\n",
            "German: Dieser Vorwurf meiner Abhängigkeit war in meinen Ohren fast zum leeren, bedeutungslosen Singsang geworden, sehr schmerzlich und bedrückend, aber nur halb verständlich.\n",
            "Actual English: This reproach of my dependence had become a vague sing-song in my ear: very painful and crushing, but only half intelligible.\n",
            "Model Translation: This draft of my ability was in my ears fast to leer, bedeutungsless Singsang became very painful and besieged, but only half understood.\n",
            "\n",
            "Example 201:\n",
            "German: Welche seltene Höflichkeit!\n",
            "Actual English: Wonderful civility this!\n",
            "Model Translation: What rare holiness!\n",
            "\n",
            "Example 301:\n",
            "German: »Ich weiß es nicht.\n",
            "Actual English: \"I don't know.\n",
            "Model Translation: I don't know.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "prompt = \"Translate German into English: \"\n",
        "predicted = []\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    german_text = dataset[i]['translation']['de']\n",
        "    prompted_text = [prompt + german_text]\n",
        "    encoded = tokenizer(prompted_text, return_tensors=\"pt\", padding=\"longest\").to(device)\n",
        "    output = model.generate(**encoded, max_new_tokens=100)\n",
        "    pred = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    predicted.append(pred)\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"\\nExample {i+1}:\")\n",
        "        print(f\"German: {german_text}\")\n",
        "        print(f\"Prediction: {pred}\")\n",
        "\n",
        "print(\"\\nSample Model Translations vs. Ground Truth:\\n\")\n",
        "for i in [100, 200, 300]:\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"German: {dataset[i]['translation']['de']}\")\n",
        "    print(f\"Actual English: {dataset[i]['translation']['en']}\")\n",
        "    print(f\"Model Translation: {predicted[i]}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8e3308a-f0ab-429a-bbe4-71b80bac168e",
      "metadata": {
        "id": "b8e3308a-f0ab-429a-bbe4-71b80bac168e"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "Translations are difficult to evaluate quantitatively and without expert human translators. One common metric is the [BLEU score](https://en.wikipedia.org/wiki/BLEU).\n",
        "\n",
        "The below example demonstrates calculating BLEU scores with the `evaluate` module from Hugging Face. You can [see the documentation here](https://huggingface.co/spaces/evaluate-metric/bleu). The first value in the results dictionary gives the score. Normally the score is reported on a scale from 0-100; this implementation reports it on a 0-1 scale. Higher values are better, but scores of 1 are not necessarily expected given the many possible ways to translate.\n",
        "\n",
        "Note that `predictions` is a list of strings, but `references` is a list of lists of strings. This is because a single predicted translation could potentially have multiple equally good reference translations. In our case however we just have the single translation per pair, so `references` will be a list of lists, each with a single element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8535dea9-e0f8-4b4d-831c-06fb4d32cca9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8535dea9-e0f8-4b4d-831c-06fb4d32cca9",
        "outputId": "4fa0a9eb-9e64-49e0-d2a1-1550a7be9003",
        "tags": []
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evaluate'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run but you do not need to modify this code\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mevaluate\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe black cat is sleeping in the sun by the window\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe dog runs in the field while it rains\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      7\u001b[0m references \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe black cat is sleeps on the sun by the window\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m               [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe dog run in the field while it rain\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evaluate'"
          ]
        }
      ],
      "source": [
        "# run but you do not need to modify this code\n",
        "\n",
        "import evaluate\n",
        "\n",
        "predictions = [\"the black cat is sleeping in the sun by the window\",\n",
        "               \"the dog runs in the field while it rains\"]\n",
        "references = [[\"the black cat is sleeps on the sun by the window\"],\n",
        "              [\"the dog run in the field while it rain\"]]\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "results = bleu.compute(predictions=predictions, references=references)\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c882937-f116-45bd-bb4c-657fde8d4262",
      "metadata": {
        "id": "3c882937-f116-45bd-bb4c-657fde8d4262"
      },
      "source": [
        "**Calculate the `BLEU` score of your translations from task 2 against the real English text`. Report your results.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9495ae5a-a30c-4849-b0e4-95334a440b75",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9495ae5a-a30c-4849-b0e4-95334a440b75",
        "outputId": "4baeb00a-7681-43b0-dcc2-174e37223602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'bleu': 0.02636236611533724, 'precisions': [0.1488839987425338, 0.031028886725089258, 0.015632338141563232, 0.007285089849441476], 'brevity_penalty': 0.9788499415278665, 'length_ratio': 0.9790704832256079, 'translation_length': 15905, 'reference_length': 16245}\n"
          ]
        }
      ],
      "source": [
        "# write code for task 3 here\n",
        "refs = [dataset[i]['translation']['de'] for i in range(len(dataset))]\n",
        "scores = bleu.compute(predictions=predicted, references=refs)\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "572c4927-f698-4bf0-a5f1-9863e99643cf",
      "metadata": {
        "id": "572c4927-f698-4bf0-a5f1-9863e99643cf"
      },
      "source": [
        "## Task 4\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4848987-6ee2-408d-a96d-670f0f546ba0",
      "metadata": {
        "id": "d4848987-6ee2-408d-a96d-670f0f546ba0"
      },
      "source": [
        "In this task, study the impact of model scale on the quality of the resulting translations. Earlier we used `model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", torch_dtype=torch.float16)` to import a `flan-t5-small` model.\n",
        "\n",
        "**Use two additional models: `flan-t5-base` and `flan-t5-large` to generate translations of the same dataset. Evaluate and report the BLEU score of both translations.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "116da63c-ea78-4bb3-a2ef-d22c0089b2b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "116da63c-ea78-4bb3-a2ef-d22c0089b2b5",
        "outputId": "9c8624d0-12b8-4a97-f35f-eef2eeb1bba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Model Translations vs. Ground Truth:\n",
            "\n",
            "Example 101:\n",
            "German: Dieser Vorwurf meiner Abhängigkeit war in meinen Ohren fast zum leeren, bedeutungslosen Singsang geworden, sehr schmerzlich und bedrückend, aber nur halb verständlich.\n",
            "Actual English: This reproach of my dependence had become a vague sing-song in my ear: very painful and crushing, but only half intelligible.\n",
            "Model Translation: This draft of my own was quickly becoming a painful and painful singing, very painful and painful, but only half a logical one.\n",
            "\n",
            "Example 201:\n",
            "German: Welche seltene Höflichkeit!\n",
            "Actual English: Wonderful civility this!\n",
            "Model Translation: What rare happiness!\n",
            "\n",
            "Example 301:\n",
            "German: »Ich weiß es nicht.\n",
            "Actual English: \"I don't know.\n",
            "Model Translation: \"I don't know.\n",
            "\n",
            "\n",
            "Sample Model Translations vs. Ground Truth:\n",
            "\n",
            "Example 101:\n",
            "German: Dieser Vorwurf meiner Abhängigkeit war in meinen Ohren fast zum leeren, bedeutungslosen Singsang geworden, sehr schmerzlich und bedrückend, aber nur halb verständlich.\n",
            "Actual English: This reproach of my dependence had become a vague sing-song in my ear: very painful and crushing, but only half intelligible.\n",
            "Model Translation: This projection of my obligation became almost a sung, resounding chant in my ears, very painful and reverberating, but only half understandable.\n",
            "\n",
            "Example 201:\n",
            "German: Welche seltene Höflichkeit!\n",
            "Actual English: Wonderful civility this!\n",
            "Model Translation: What rare holiness!\n",
            "\n",
            "Example 301:\n",
            "German: »Ich weiß es nicht.\n",
            "Actual English: \"I don't know.\n",
            "Model Translation: »I don't know.\n",
            "\n",
            "Scores - base: {'bleu': 0.02518582585334226, 'precisions': [0.17115983307941976, 0.034239539820584815, 0.014742363030689631, 0.006312853262864274], 'brevity_penalty': 0.9267776539679986, 'length_ratio': 0.9293321021852878, 'translation_length': 15097, 'reference_length': 16245}\n",
            "Scores - large: {'bleu': 0.023598287669340835, 'precisions': [0.16778791713848, 0.03197133604354716, 0.013915649753800044, 0.005768377458955776], 'brevity_penalty': 0.9212146456180873, 'length_ratio': 0.9241612803939674, 'translation_length': 15013, 'reference_length': 16245}\n"
          ]
        }
      ],
      "source": [
        "# write code for task 4 here\n",
        "model_base = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\", torch_dtype=torch.float16)\n",
        "model_base.to(device)\n",
        "predicted_base = []\n",
        "for i in range(len(dataset)):\n",
        "    german_text = dataset[i]['translation']['de']\n",
        "    prompted_text = [prompt + german_text]\n",
        "    encoded = tokenizer(prompted_text, return_tensors=\"pt\", padding=\"longest\").to(device)\n",
        "    output = model_base.generate(**encoded, max_new_tokens=100)\n",
        "    pred = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    predicted_base.append(pred)\n",
        "    # if (i + 1) % 50 == 0:\n",
        "    #     print(f\"\\nExample {i+1}:\")\n",
        "    #     print(f\"German: {german_text}\")\n",
        "    #     print(f\"Prediction: {pred}\")\n",
        "\n",
        "print(\"\\nSample Model Translations vs. Ground Truth:\\n\")\n",
        "for i in [100, 200, 300]:\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"German: {dataset[i]['translation']['de']}\")\n",
        "    print(f\"Actual English: {dataset[i]['translation']['en']}\")\n",
        "    print(f\"Model Translation: {predicted_base[i]}\\n\")\n",
        "\n",
        "\n",
        "model_large = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", torch_dtype=torch.float16)\n",
        "model_large.to(device)\n",
        "predicted_large = []\n",
        "for i in range(len(dataset)):\n",
        "    german_text = dataset[i]['translation']['de']\n",
        "    prompted_text = [prompt + german_text]\n",
        "    encoded = tokenizer(prompted_text, return_tensors=\"pt\", padding=\"longest\").to(device)\n",
        "    output = model_large.generate(**encoded, max_new_tokens=100)\n",
        "    pred = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    predicted_large.append(pred)\n",
        "    # if (i + 1) % 50 == 0:\n",
        "    #     print(f\"\\nExample {i+1}:\")\n",
        "    #     print(f\"German: {german_text}\")\n",
        "    #     print(f\"Prediction: {pred}\")\n",
        "\n",
        "print(\"\\nSample Model Translations vs. Ground Truth:\\n\")\n",
        "for i in [100, 200, 300]:\n",
        "    print(f\"Example {i+1}:\")\n",
        "    print(f\"German: {dataset[i]['translation']['de']}\")\n",
        "    print(f\"Actual English: {dataset[i]['translation']['en']}\")\n",
        "    print(f\"Model Translation: {predicted_large[i]}\\n\")\n",
        "\n",
        "scores_base = bleu.compute(predictions=predicted_base, references=refs)\n",
        "print(f\"Scores - base: {scores_base}\")\n",
        "scores_large = bleu.compute(predictions=predicted_large, references=refs)\n",
        "print(f\"Scores - large: {scores_large}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06a6a534d71741518dc28e5506e27522": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b9fbfc50a4f411a98f091e6c2e16aa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_630c8e79ea0f416694cfe3e04bf74867",
              "IPY_MODEL_4fcbad5d03a7430f889c3588c2ae64ef",
              "IPY_MODEL_56a5ccb809744c90aa676c8cd28debc8"
            ],
            "layout": "IPY_MODEL_c59d8103cd5f434fa4fe3c5fef0586c1"
          }
        },
        "0c160d072ae8416697da2d35ea3a68d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fb827fe443044718431db65056eec56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1322a370230c4104a4c42a4389717b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ce7d1ef14c1447ca9105d8d04c6cc8e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac8f23924d30434b831ecbc846e4a24f",
            "value": " 2.42M/2.42M [00:00&lt;00:00, 10.9MB/s]"
          }
        },
        "1dd4fb7a2bdf454594ae07c910e259e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2070ccc3e8c046108b40f16db86c666f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2133d9f9442f454cb209dc5e66178e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22afb012676c4f18b46394b7b94a0f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2348d91acd1243b28ccb4b66d03dda6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "310ba1d9f53f4029a4f5a93b12a51266": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ce7d1ef14c1447ca9105d8d04c6cc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47cbbb9448084ad4a508eb013b04f539": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a19f00b7c7401f9061ae3579979a17",
            "placeholder": "​",
            "style": "IPY_MODEL_2133d9f9442f454cb209dc5e66178e42",
            "value": " 28.1k/28.1k [00:00&lt;00:00, 782kB/s]"
          }
        },
        "4995892cd8be4bf3bf9deb6c83730172": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6667f8f1114022922416192ffed592": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcbad5d03a7430f889c3588c2ae64ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e78ddf247b2a418592c3c616c4493af5",
            "max": 2201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c29ea8b153844dfca2e64c2a58bdb72a",
            "value": 2201
          }
        },
        "550733b1c9e54b9ab6afb1a43cce74e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22afb012676c4f18b46394b7b94a0f8d",
            "max": 2424064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ce15fb683934db8b87a346daff2ae18",
            "value": 2424064
          }
        },
        "56a5ccb809744c90aa676c8cd28debc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4995892cd8be4bf3bf9deb6c83730172",
            "placeholder": "​",
            "style": "IPY_MODEL_f8736b4a52c243b993dfdfa3ef10ff54",
            "value": " 2.20k/2.20k [00:00&lt;00:00, 267kB/s]"
          }
        },
        "583c437a21254e1bb49bec206935d884": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1ea0eaea24543dfa3d3932756a0665c",
              "IPY_MODEL_550733b1c9e54b9ab6afb1a43cce74e0",
              "IPY_MODEL_1322a370230c4104a4c42a4389717b2b"
            ],
            "layout": "IPY_MODEL_8efc428d76234b9595a0e634b6075ebf"
          }
        },
        "60a75d8c9af44ba6951e365f682155ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60a891c6e6754d39911ac41fe453d830",
              "IPY_MODEL_f67d1244a96448f0b20fd0dc07a6a53a",
              "IPY_MODEL_47cbbb9448084ad4a508eb013b04f539"
            ],
            "layout": "IPY_MODEL_d33f105722fd49bfac56a9df4a60fcad"
          }
        },
        "60a891c6e6754d39911ac41fe453d830": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65db3bd502ff492ab657e795cf06e1db",
            "placeholder": "​",
            "style": "IPY_MODEL_a2c9c4013ede49f9ae9c0c0f6ebd004f",
            "value": "README.md: 100%"
          }
        },
        "630c8e79ea0f416694cfe3e04bf74867": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef25545468984f8ca7897471a38f74c3",
            "placeholder": "​",
            "style": "IPY_MODEL_787e6d629b8b48d2bd1b13eb304e2ab2",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "65db3bd502ff492ab657e795cf06e1db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700546c4e4fc4693bbe1c2f781543b7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd06aed400934fc2a20c1462d546ea48",
              "IPY_MODEL_df75454dcfd44366b043a05999d3ddf3",
              "IPY_MODEL_7b102c61daec4c2c863ab39f145738cc"
            ],
            "layout": "IPY_MODEL_1dd4fb7a2bdf454594ae07c910e259e9"
          }
        },
        "787e6d629b8b48d2bd1b13eb304e2ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b102c61daec4c2c863ab39f145738cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6667f8f1114022922416192ffed592",
            "placeholder": "​",
            "style": "IPY_MODEL_310ba1d9f53f4029a4f5a93b12a51266",
            "value": " 792k/792k [00:00&lt;00:00, 16.3MB/s]"
          }
        },
        "8efc428d76234b9595a0e634b6075ebf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f8f4b6ced684bf0a8b9c5518e936dde": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca6dfde179c44329f39863e87ed67b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ce15fb683934db8b87a346daff2ae18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2c9c4013ede49f9ae9c0c0f6ebd004f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac8f23924d30434b831ecbc846e4a24f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aedbf272bd43424685913c88be88e49a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afcb8f985d4140c8a8e87e69881bd72c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1ea0eaea24543dfa3d3932756a0665c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f35adc196446998284a983ee370e29",
            "placeholder": "​",
            "style": "IPY_MODEL_0c160d072ae8416697da2d35ea3a68d2",
            "value": "tokenizer.json: 100%"
          }
        },
        "bbf890869d0945c6ab5bdd59402814f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c29ea8b153844dfca2e64c2a58bdb72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c459b8e0d847455caa171aa11410dd23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb827fe443044718431db65056eec56",
            "placeholder": "​",
            "style": "IPY_MODEL_2070ccc3e8c046108b40f16db86c666f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c59d8103cd5f434fa4fe3c5fef0586c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6fafd3db4c4499abb4192ce214567d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce0bf6c0eb594ce99e70a8d582d082c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6fafd3db4c4499abb4192ce214567d",
            "placeholder": "​",
            "style": "IPY_MODEL_06a6a534d71741518dc28e5506e27522",
            "value": " 2.54k/2.54k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "d0c3ea5be13b478a80abbfb5974472ce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a19f00b7c7401f9061ae3579979a17": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32ef4e06545455d92db3ecfe7d39bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afcb8f985d4140c8a8e87e69881bd72c",
            "max": 2537,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aedbf272bd43424685913c88be88e49a",
            "value": 2537
          }
        },
        "d33f105722fd49bfac56a9df4a60fcad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da5acdce8b224c9ca21e7a3a2331779b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df75454dcfd44366b043a05999d3ddf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da5acdce8b224c9ca21e7a3a2331779b",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ca6dfde179c44329f39863e87ed67b7",
            "value": 791656
          }
        },
        "e78ddf247b2a418592c3c616c4493af5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef25545468984f8ca7897471a38f74c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f35adc196446998284a983ee370e29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f67d1244a96448f0b20fd0dc07a6a53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f8f4b6ced684bf0a8b9c5518e936dde",
            "max": 28064,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbf890869d0945c6ab5bdd59402814f3",
            "value": 28064
          }
        },
        "f8736b4a52c243b993dfdfa3ef10ff54": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b07b72eb95495e87e98809711859b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a85abb784f493c84c90ef45daf53ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c459b8e0d847455caa171aa11410dd23",
              "IPY_MODEL_d32ef4e06545455d92db3ecfe7d39bb1",
              "IPY_MODEL_ce0bf6c0eb594ce99e70a8d582d082c1"
            ],
            "layout": "IPY_MODEL_2348d91acd1243b28ccb4b66d03dda6d"
          }
        },
        "fd06aed400934fc2a20c1462d546ea48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c3ea5be13b478a80abbfb5974472ce",
            "placeholder": "​",
            "style": "IPY_MODEL_f8b07b72eb95495e87e98809711859b0",
            "value": "spiece.model: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
